{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"86534e84","cell_type":"markdown","source":"# Fine-tuning an LLM using Quantisation and LoRA (QLoRA)\n","metadata":{"id":"86534e84"}},{"id":"447cf947-863c-49ae-b72b-4aaf50b66937","cell_type":"markdown","source":"In this notebook I will be fine-tuning \"TinyLlama-1.1B-Chat-v1.0\" using 4-bit quantisation and LoRA (Low Rank Adaptation) for having conversations in Hinglish with the user.","metadata":{}},{"id":"92c11119-c6d2-4fc6-b67a-933d2c81319c","cell_type":"code","source":"%pip install -q -U bitsandbytes\n%pip install -q -U transformers\n%pip install -q -U peft\n%pip install -q -U accelerate\n%pip install -q datasets","metadata":{"id":"92c11119-c6d2-4fc6-b67a-933d2c81319c","outputId":"1ed8a8cf-f9a3-4b00-c31e-42421e027ba5","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T09:59:07.011451Z","iopub.status.idle":"2025-07-05T10:00:54.056112Z","shell.execute_reply.started":"2025-07-05T09:59:07.011922Z","shell.execute_reply":"2025-07-05T10:00:54.055194Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.3/472.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m952.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nCollecting trl\n  Downloading trl-0.19.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.8.1)\nRequirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (3.6.0)\nRequirement already satisfied: transformers>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.53.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.6.0+cu124)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.31.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl) (0.21.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.4.26)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2024.2.0)\nDownloading trl-0.19.0-py3-none-any.whl (375 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: trl\nSuccessfully installed trl-0.19.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"id":"48a6928c-eb3a-4c6d-a38c-f852e8891b2a","cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value = user_secrets.get_secret(\"huggingface\")\n\nfrom huggingface_hub import login\nlogin(token=secret_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:00:54.057597Z","iopub.execute_input":"2025-07-05T10:00:54.057839Z","iopub.status.idle":"2025-07-05T10:00:54.761528Z","shell.execute_reply.started":"2025-07-05T10:00:54.057816Z","shell.execute_reply":"2025-07-05T10:00:54.760948Z"}},"outputs":[],"execution_count":2},{"id":"10e95375-51e9-4a92-9e40-f56028d2b15c","cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\nfrom peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, TaskType\nfrom datasets import load_dataset, Dataset\nimport transformers\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:04:47.628586Z","iopub.execute_input":"2025-07-05T10:04:47.628913Z","iopub.status.idle":"2025-07-05T10:04:47.633256Z","shell.execute_reply.started":"2025-07-05T10:04:47.628891Z","shell.execute_reply":"2025-07-05T10:04:47.632481Z"}},"outputs":[],"execution_count":4},{"id":"5b8404bd-6517-41ab-99bd-ef91560d3f72","cell_type":"code","source":"# Dry running model\n\nmodel_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n\nmodel_og = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=torch.float16)\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\nprompt = \"\"\"<start_of_turn>user\nOnline shopping mein paise bachaane ke liye kya tareeke hain?<end_of_turn>\n<start_of_turn>model\"\"\"\ninput_ids = tokenizer(text=prompt, return_tensors=\"pt\")\noutputs = model_og.generate(**input_ids, max_new_tokens=512)\ntext = tokenizer.batch_decode(\n    outputs,\n    skip_special_tokens=True,\n    clean_up_tokenization_spaces=True\n)\nprint(text[0])\n","metadata":{"id":"5b8404bd-6517-41ab-99bd-ef91560d3f72","outputId":"aec27f9c-9932-4aeb-bc66-12acaef9728d","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:45:00.611936Z","iopub.execute_input":"2025-07-05T12:45:00.612466Z","iopub.status.idle":"2025-07-05T12:45:07.419791Z","shell.execute_reply.started":"2025-07-05T12:45:00.612436Z","shell.execute_reply":"2025-07-05T12:45:07.419118Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:2497: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"<start_of_turn>user\nOnline shopping mein paise bachaane ke liye kya tareeke hain?<end_of_turn>\n<start_of_turn>model:\nSure, I can help you with that. The cost of online shopping varies depending on the product, the delivery method, and the seller. However, on average, you can expect to pay anywhere from 10% to 20% less than what you would pay in-store. This is because online shopping eliminates the need for physical stores, transportation costs, and the need for staff to manage inventory. Additionally, online shopping allows you to compare prices and choose the best deal for your budget. So, if you're looking to save money on your online shopping, online shopping is definitely the way to go!\n","output_type":"stream"}],"execution_count":22},{"id":"55173d26-d86c-40bc-8b44-76893d509ffb","cell_type":"markdown","source":"We can see that the model does not respond in Hinglish for queriest given in Hinglish. Therefore we can fine-tune the model to respond to any user queries in Hinglish.","metadata":{}},{"id":"dcd91121-3345-41d4-b3fc-7460d962036f","cell_type":"code","source":"# Loading the model with 4-bit quantisation\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\", torch_dtype=torch.float16)","metadata":{"id":"914484bd-acef-4c04-9971-ddc9c86f0f8a","execution":{"iopub.status.busy":"2025-07-05T10:05:29.898577Z","iopub.execute_input":"2025-07-05T10:05:29.898825Z","iopub.status.idle":"2025-07-05T10:05:33.579261Z","shell.execute_reply.started":"2025-07-05T10:05:29.898808Z","shell.execute_reply":"2025-07-05T10:05:33.578436Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"7f1750b8-6986-4e5b-8bcb-c47667874954","cell_type":"code","source":"# Enabling gradient checkpointing for memory efficient training\n\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"id":"7f1750b8-6986-4e5b-8bcb-c47667874954","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:05:39.562675Z","iopub.execute_input":"2025-07-05T10:05:39.563416Z","iopub.status.idle":"2025-07-05T10:05:39.572495Z","shell.execute_reply.started":"2025-07-05T10:05:39.563389Z","shell.execute_reply":"2025-07-05T10:05:39.571767Z"}},"outputs":[],"execution_count":7},{"id":"3d6e3195-f00e-4d78-a9ea-f3086dd5f72f","cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )","metadata":{"id":"3d6e3195-f00e-4d78-a9ea-f3086dd5f72f","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:05:39.573531Z","iopub.execute_input":"2025-07-05T10:05:39.573849Z","iopub.status.idle":"2025-07-05T10:05:39.581754Z","shell.execute_reply.started":"2025-07-05T10:05:39.573831Z","shell.execute_reply":"2025-07-05T10:05:39.581048Z"}},"outputs":[],"execution_count":8},{"id":"42467550-8d46-4e6e-aa1e-59cdb6e1e387","cell_type":"code","source":"# Original model architecture\n\nprint(model)","metadata":{"id":"42467550-8d46-4e6e-aa1e-59cdb6e1e387","outputId":"655dd809-1c7b-4614-8fc0-ad44ba21cddc","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:05:39.582787Z","iopub.execute_input":"2025-07-05T10:05:39.583022Z","iopub.status.idle":"2025-07-05T10:05:39.594075Z","shell.execute_reply.started":"2025-07-05T10:05:39.582982Z","shell.execute_reply":"2025-07-05T10:05:39.593498Z"}},"outputs":[{"name":"stdout","text":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(32000, 2048)\n    (layers): ModuleList(\n      (0-21): 22 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n          (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n)\n","output_type":"stream"}],"execution_count":9},{"id":"f6f3270c-e815-4d2d-8610-97551de04435","cell_type":"code","source":"# Defining LoRA configuration\n\nconfig = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM\n)\n\nmodel = get_peft_model(model, config)\nprint_trainable_parameters(model)","metadata":{"id":"f6f3270c-e815-4d2d-8610-97551de04435","outputId":"63cb96f5-f6e6-4ff6-a7a8-9025338e81d7","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:05:39.594768Z","iopub.execute_input":"2025-07-05T10:05:39.594925Z","iopub.status.idle":"2025-07-05T10:05:39.725033Z","shell.execute_reply.started":"2025-07-05T10:05:39.594913Z","shell.execute_reply":"2025-07-05T10:05:39.724236Z"}},"outputs":[{"name":"stdout","text":"trainable params: 2252800 || all params: 617859072 || trainable%: 0.36461389046335796\n","output_type":"stream"}],"execution_count":10},{"id":"3695bba3-44f8-4642-9721-c869b70eda76","cell_type":"code","source":"# Loading Dataset\n\n# Enable streaming mode (faster)\nstreamed_dataset = load_dataset(\"maya-research/IndicVault\", \"Hinglish\", split=\"train\", streaming=True)\n\n# Convert the first 12,000 streamed samples into a regular Dataset\nfrom itertools import islice\nstreamed_subset = list(islice(streamed_dataset, 12000))\n\n# Convert to Hugging Face Dataset format\ndataset = Dataset.from_list(streamed_subset)\n\n# Now split it into train and val sets\ntrain_data = dataset.select(range(5000))\nval_data = dataset.select(range(5000, 6000))\n\ntrain_data, val_data","metadata":{"id":"3695bba3-44f8-4642-9721-c869b70eda76","outputId":"ae0ec618-193b-4eab-e183-ef1a4bd99a3d","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:05:39.726621Z","iopub.execute_input":"2025-07-05T10:05:39.726837Z","iopub.status.idle":"2025-07-05T10:05:55.705780Z","shell.execute_reply.started":"2025-07-05T10:05:39.726822Z","shell.execute_reply":"2025-07-05T10:05:55.705020Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7d509cde8b0437ca1a387663780445e"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['question', 'response'],\n     num_rows: 5000\n }),\n Dataset({\n     features: ['question', 'response'],\n     num_rows: 1000\n }))"},"metadata":{}}],"execution_count":11},{"id":"31a2d9d6","cell_type":"code","source":"# Preprocess responses (tokenize responses and convert them into pytorch tensors)\n\ndef preprocess_quotes(example):\n    return tokenizer(\n        example[\"response\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512\n    )\ntrain_data = train_data.map(preprocess_quotes, batched=True)\nval_data = val_data.map(preprocess_quotes, batched=True)\n\ncolumns = [\"input_ids\", \"attention_mask\"]\ntrain_data.set_format(type=\"torch\", columns=columns)\nval_data.set_format(type=\"torch\", columns=columns)\n","metadata":{"colab":{"referenced_widgets":["9d73007aa6a54fafa1325d11a004eafd"]},"id":"31a2d9d6","outputId":"b1cd6ee7-af88-4f85-8ce6-23b66c0cc56d","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:05:55.706622Z","iopub.execute_input":"2025-07-05T10:05:55.706908Z","iopub.status.idle":"2025-07-05T10:06:03.121901Z","shell.execute_reply.started":"2025-07-05T10:05:55.706885Z","shell.execute_reply":"2025-07-05T10:06:03.121318Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"966a785205db43aebc5932d58b682f29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a8febb046be402b881bcb60f64601b1"}},"metadata":{}}],"execution_count":12},{"id":"4304f7a2","cell_type":"code","source":"# Prepare a padded training batch with input IDs and labels for causal language modeling\n\ndata_collator = transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\nbatch = data_collator([train_data[i] for i in range(2)])\nprint(batch[\"input_ids\"][0])\nprint(batch[\"labels\"][0])","metadata":{"id":"4304f7a2","outputId":"047b5626-d718-4816-8cd4-5306d5a30f18","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:06:03.122617Z","iopub.execute_input":"2025-07-05T10:06:03.122800Z","iopub.status.idle":"2025-07-05T10:06:03.139550Z","shell.execute_reply.started":"2025-07-05T10:06:03.122786Z","shell.execute_reply":"2025-07-05T10:06:03.138687Z"}},"outputs":[{"name":"stdout","text":"tensor([    1,  5952,   273, 29892, 13181, 29895,   352, 29991,  4231,   273,\n         1455, 29822, 11157, 10856,  1056,   338, 14909,  1950, 29892, 17078,\n          270,   354,   406, 29899, 29881,   354,   406, 10856,  1056,  7251,\n         1900,   447, 29875, 29889, 29871,   476,  7768,   696,  3522, 10466,\n        12902, 29875,   447, 29875, 29892,  2362,   413,   987,  2560,  6576,\n         1101, 10856,   484,   447, 29875, 29889, 29871,   612,   801,   273,\n        14921, 29871, 29896, 29900, 29899,  3149,  3814,   447, 29875, 29892,\n         4780, 29899,   412,  8995,   260,   598, 29872,   446,   409, 29901,\n           13,    13,  1068, 12881,   273,  1455,  3295, 13326,   457,  8383,\n         8222,   484, 13680, 29871, 29896, 29900, 29899,  5228,  8402,   313,\n        29923, 29895, 29881,   398, 14624,   379,   292,  1674,  2191,   262,\n        14366,  1068,    13,    13, 29896, 29889,  3579, 29925,  1759, 29874,\n          476,   801,   273, 14021, 16790, 29874,   379,  1794, 29892,   897,\n        29895,  1251,   323,  1148, 24246, 29875, 29991, 29901,  1068, 11775,\n          344,  1236, 29882,   280,  8007, 29882,  5702,   413,  8854,  8506,\n        21622, 29882,  2518,   282,  1759, 29874,   432,  7340,   413,   801,\n          273,  1153,  2350,   447, 29875, 29889, 29871,  2401, 29879,   447,\n          262,   289,   801,   329,   872,   598,   313,  1764,   895,  9008,\n          592,   262,   289,  2918,  4240, 29899,   262,   298,   866,   447,\n          262, 29897,  9343,  1374,   381, 14921,  2560,   652,   653,   592,\n          262,  4188, 29882,   658, 29889, 29871,   435,   370,   282,   532,\n          521,   744,  3249,  1055, 29892,   304, 29882, 19253, 11755,   269,\n          557,   941,   447, 29875,  8506,   525,   279,   276, 29892,   372,\n         1056,   304, 29882,   343,   801,   273, 11430,   330,  9010, 20714,\n        29871, 10134, 29882,   937,  4331,   447, 29875, 29892,   289, 23535,\n        29889,    13,    13, 29906, 29889,  3579, 29933,   566,   657,   350,\n         1648,  4309, 29892,   350,  2209, 29991, 29901,  1068, 29871, 16462,\n        23562,   289,  1648, 29877, 29889, 29871, 10134, 29882, 12902, 29875,\n         8506, 14921, 29881,   398, 12912,   333,   281,  2883, 29892,   541,\n        14921, 12164,  2969,   304, 29882,  5089,  8506,   413,   277,  1056,\n        17869,   447, 29875, 17078,   413,   277,  1056,   413, 29882,  1279,\n        29874, 10856,  1056,   447, 29875, 29889, 29871, 12027, 11259,  5812,\n        13997,   592,   262, 16429, 10856,   658,   448, 21370,  5338,   281,\n          744,   313,  7771, 29892,   289,  6090, 29892,  4071, 29883,   708,\n        29897, 17078,   525, 16533,   304,   505, 29915,   281,   744,   313,\n        29872,  1218,   714, 29892, 22684,   358,   467, 29871,  7038,   657,\n          409,   282,   532,   521,   284,   941,   447, 29875,  8506,   413,\n          801,   273,  5700, 10856,   269, 17230,  5089, 29889,    13,    13,\n        29941, 29889,  3579, 12881,   273,  1455,  2921,  1338,  3789,  3467,\n        29877, 29892,   612,  4025, 29991, 29901,  1068, 29871,  2921,  1338,\n         1589,   289,  1099,   413,  3761,   611,  1362, 29973, 29871, 13899,\n        29899,  8489, 14433,   313,  1764,   895,   302,  9010,  9008,   301,\n         2386,   447, 29875, 29871, 29953,   611, 29882,   457,   592,   262,\n        29897, 17078,  1472, 29899,  8489, 14433,   313,  2267, 19211,  1589,\n          619,  4099,  4078, 10856,  1056,   447, 29875, 29892,   330,  8222,\n          413,  8222,   333,  1056,   447, 29875, 29897,   731,   413,  8854,\n        29889, 29871,  2921,  1338,  4207,   479,   304, 29882, 17385,   362,\n         1153,   354,  3249,  4078, 10856,   484, 13560, 29889,    13,    13,\n        29946, 29889,  3579, 29903,   485,   886,  8224, 15854,  2454,   350,\n         1648, 29877, 29901,  1068, 29871, 10134, 29882,  1900,  8938,   447,\n        29875, 29991, 29871,  6225,   484,  9124,  3633,   409, 18428,  6782,\n          731,   413])\ntensor([    1,  5952,   273, 29892, 13181, 29895,   352, 29991,  4231,   273,\n         1455, 29822, 11157, 10856,  1056,   338, 14909,  1950, 29892, 17078,\n          270,   354,   406, 29899, 29881,   354,   406, 10856,  1056,  7251,\n         1900,   447, 29875, 29889, 29871,   476,  7768,   696,  3522, 10466,\n        12902, 29875,   447, 29875, 29892,  2362,   413,   987,  2560,  6576,\n         1101, 10856,   484,   447, 29875, 29889, 29871,   612,   801,   273,\n        14921, 29871, 29896, 29900, 29899,  3149,  3814,   447, 29875, 29892,\n         4780, 29899,   412,  8995,   260,   598, 29872,   446,   409, 29901,\n           13,    13,  1068, 12881,   273,  1455,  3295, 13326,   457,  8383,\n         8222,   484, 13680, 29871, 29896, 29900, 29899,  5228,  8402,   313,\n        29923, 29895, 29881,   398, 14624,   379,   292,  1674,  2191,   262,\n        14366,  1068,    13,    13, 29896, 29889,  3579, 29925,  1759, 29874,\n          476,   801,   273, 14021, 16790, 29874,   379,  1794, 29892,   897,\n        29895,  1251,   323,  1148, 24246, 29875, 29991, 29901,  1068, 11775,\n          344,  1236, 29882,   280,  8007, 29882,  5702,   413,  8854,  8506,\n        21622, 29882,  2518,   282,  1759, 29874,   432,  7340,   413,   801,\n          273,  1153,  2350,   447, 29875, 29889, 29871,  2401, 29879,   447,\n          262,   289,   801,   329,   872,   598,   313,  1764,   895,  9008,\n          592,   262,   289,  2918,  4240, 29899,   262,   298,   866,   447,\n          262, 29897,  9343,  1374,   381, 14921,  2560,   652,   653,   592,\n          262,  4188, 29882,   658, 29889, 29871,   435,   370,   282,   532,\n          521,   744,  3249,  1055, 29892,   304, 29882, 19253, 11755,   269,\n          557,   941,   447, 29875,  8506,   525,   279,   276, 29892,   372,\n         1056,   304, 29882,   343,   801,   273, 11430,   330,  9010, 20714,\n        29871, 10134, 29882,   937,  4331,   447, 29875, 29892,   289, 23535,\n        29889,    13,    13, 29906, 29889,  3579, 29933,   566,   657,   350,\n         1648,  4309, 29892,   350,  2209, 29991, 29901,  1068, 29871, 16462,\n        23562,   289,  1648, 29877, 29889, 29871, 10134, 29882, 12902, 29875,\n         8506, 14921, 29881,   398, 12912,   333,   281,  2883, 29892,   541,\n        14921, 12164,  2969,   304, 29882,  5089,  8506,   413,   277,  1056,\n        17869,   447, 29875, 17078,   413,   277,  1056,   413, 29882,  1279,\n        29874, 10856,  1056,   447, 29875, 29889, 29871, 12027, 11259,  5812,\n        13997,   592,   262, 16429, 10856,   658,   448, 21370,  5338,   281,\n          744,   313,  7771, 29892,   289,  6090, 29892,  4071, 29883,   708,\n        29897, 17078,   525, 16533,   304,   505, 29915,   281,   744,   313,\n        29872,  1218,   714, 29892, 22684,   358,   467, 29871,  7038,   657,\n          409,   282,   532,   521,   284,   941,   447, 29875,  8506,   413,\n          801,   273,  5700, 10856,   269, 17230,  5089, 29889,    13,    13,\n        29941, 29889,  3579, 12881,   273,  1455,  2921,  1338,  3789,  3467,\n        29877, 29892,   612,  4025, 29991, 29901,  1068, 29871,  2921,  1338,\n         1589,   289,  1099,   413,  3761,   611,  1362, 29973, 29871, 13899,\n        29899,  8489, 14433,   313,  1764,   895,   302,  9010,  9008,   301,\n         2386,   447, 29875, 29871, 29953,   611, 29882,   457,   592,   262,\n        29897, 17078,  1472, 29899,  8489, 14433,   313,  2267, 19211,  1589,\n          619,  4099,  4078, 10856,  1056,   447, 29875, 29892,   330,  8222,\n          413,  8222,   333,  1056,   447, 29875, 29897,   731,   413,  8854,\n        29889, 29871,  2921,  1338,  4207,   479,   304, 29882, 17385,   362,\n         1153,   354,  3249,  4078, 10856,   484, 13560, 29889,    13,    13,\n        29946, 29889,  3579, 29903,   485,   886,  8224, 15854,  2454,   350,\n         1648, 29877, 29901,  1068, 29871, 10134, 29882,  1900,  8938,   447,\n        29875, 29991, 29871,  6225,   484,  9124,  3633,   409, 18428,  6782,\n          731,   413])\n","output_type":"stream"}],"execution_count":13},{"id":"01092a50","cell_type":"code","source":"tokenizer.padding_side = \"right\"\ntokenizer.pad_token = tokenizer.eos_token\n\nimport torch.utils.checkpoint\ntorch.utils.checkpoint.use_reentrant = False\n\n# Hyperparameters\nbatch_size = 8\nlr = 2e-4\nnum_epochs = 5\n\n# Training loop using API from Hugging Face\ntrainer = transformers.Trainer(\n    model=model,\n    train_dataset=train_data,\n    eval_dataset=val_data,\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=batch_size,\n        per_device_eval_batch_size=batch_size,\n        gradient_accumulation_steps=2,\n        num_train_epochs=num_epochs,\n        learning_rate=lr,\n        bf16=False,\n        fp16=True,\n        logging_steps=100,\n        weight_decay=0.01,\n        warmup_ratio=0.03,\n        logging_strategy=\"epoch\",\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n        output_dir=\"outputs\",\n        optim=\"paged_adamw_8bit\",\n        report_to=\"tensorboard\",\n        logging_dir=\"outputs/logs\",\n    ),\n    data_collator = data_collator ,\n)\n\nmodel.config.use_cache = False\ntrainer.train()","metadata":{"id":"01092a50","outputId":"1f8f0396-8e85-4678-e093-209608c47347","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:08:18.467596Z","iopub.execute_input":"2025-07-05T10:08:18.467865Z","iopub.status.idle":"2025-07-05T12:22:54.278912Z","shell.execute_reply.started":"2025-07-05T10:08:18.467847Z","shell.execute_reply":"2025-07-05T12:22:54.278162Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1565' max='1565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1565/1565 2:14:30, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.289900</td>\n      <td>2.071295</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.916700</td>\n      <td>1.919860</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.793300</td>\n      <td>1.846511</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.726300</td>\n      <td>1.809888</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.689600</td>\n      <td>1.795478</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1565, training_loss=1.8831643589007587, metrics={'train_runtime': 8075.2823, 'train_samples_per_second': 3.096, 'train_steps_per_second': 0.194, 'total_flos': 7.96235661312e+16, 'train_loss': 1.8831643589007587, 'epoch': 5.0})"},"metadata":{}}],"execution_count":16},{"id":"b094490a","cell_type":"code","source":"model.config.pad_token_id == tokenizer.eos_token_id","metadata":{"id":"b094490a","outputId":"6a9bf631-103b-461c-ee75-ee8507c43f24","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:25:58.345184Z","iopub.execute_input":"2025-07-05T12:25:58.345449Z","iopub.status.idle":"2025-07-05T12:25:58.350553Z","shell.execute_reply.started":"2025-07-05T12:25:58.345432Z","shell.execute_reply":"2025-07-05T12:25:58.349826Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":17},{"id":"85cfdf4a-5fdb-44a4-94b2-f28c49e67c64","cell_type":"code","source":"model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\nmodel_to_save.save_pretrained(\"outputs\")","metadata":{"id":"85cfdf4a-5fdb-44a4-94b2-f28c49e67c64","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:26:34.700757Z","iopub.execute_input":"2025-07-05T12:26:34.701455Z","iopub.status.idle":"2025-07-05T12:26:34.918454Z","shell.execute_reply.started":"2025-07-05T12:26:34.701427Z","shell.execute_reply":"2025-07-05T12:26:34.917894Z"}},"outputs":[],"execution_count":19},{"id":"f94bdc0b","cell_type":"markdown","source":"### Quantitative Analysis","metadata":{"id":"f94bdc0b"}},{"id":"d5150f19","cell_type":"code","source":"import math\n\neval_results = trainer.evaluate()\neval_loss = eval_results[\"eval_loss\"]\nperplexity = math.exp(eval_loss)\n\nprint(f\"Perplexity: {perplexity:.2f}\")\n","metadata":{"id":"d5150f19","outputId":"7644f5dd-a93e-4988-bc65-0cc1cbc0e80f","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T12:26:44.936055Z","iopub.execute_input":"2025-07-05T12:26:44.936723Z","iopub.status.idle":"2025-07-05T12:28:18.706901Z","shell.execute_reply.started":"2025-07-05T12:26:44.936703Z","shell.execute_reply":"2025-07-05T12:28:18.705957Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 01:32]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Perplexity: 6.02\n","output_type":"stream"}],"execution_count":20},{"id":"38b4d0f7","cell_type":"markdown","source":"**Perplexity = 6.02** --> This means the model, on average, chooses between 6 equally likely options for the next word.","metadata":{"id":"38b4d0f7"}},{"id":"79a4f2a1","cell_type":"markdown","source":"### Qualitative Analysis","metadata":{"id":"79a4f2a1"}},{"id":"b8d00437-41b0-4ef7-83e6-ef0ae526bc5a","cell_type":"code","source":"# Load best model\nfrom peft import PeftModel\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\n# Load base model and tokenizer\nbase_model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\ntokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n\n# Load LoRA weights\nmodel = PeftModel.from_pretrained(base_model, \"/kaggle/working/outputs/checkpoint-1565\")\nmodel = model.merge_and_unload()  # Merges LoRA into base weights for evaluation\n\nmodel.eval()\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:41:26.160970Z","iopub.execute_input":"2025-07-05T15:41:26.161550Z","iopub.status.idle":"2025-07-05T15:41:29.022495Z","shell.execute_reply.started":"2025-07-05T15:41:26.161528Z","shell.execute_reply":"2025-07-05T15:41:29.021736Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(32000, 2048)\n        (layers): ModuleList(\n          (0-21): 22 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":73},{"id":"3f0277c3-6c1b-440c-98f3-af550616d16f","cell_type":"code","source":"import pandas as pd\n\nresults = []\n\nfor i in range(5):\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user\",\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"{val_data['question'][i]}\",\n        },\n    ]\n\n    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer(text=prompt, return_tensors=\"pt\", padding=True, padding_side=\"left\", truncation=True)\n    \n    with torch.autocast(\"cuda\", dtype=torch.float16):\n        output_ft = model.generate(**inputs, max_new_tokens=400,\n                                 do_sample=True,\n                                 temperature=0.5,\n                                 top_k=50,top_p=0.95,\n                                 pad_token_id=tokenizer.eos_token_id)\n        output_ft = tokenizer.batch_decode(output_ft, skip_special_tokens=True, clean_up_tokenization_spaces=True)[0].replace(prompt, \"\").strip()\n        print(f\"Fine-tuned model output {i} -\\n---------------------------\\n\", output_ft, \"\\n\")\n    \n    output_og = model_og.generate(**inputs, max_new_tokens=400,\n                                 do_sample=True,\n                                 temperature=0.5,\n                                 top_k=50,top_p=0.95,\n                                 pad_token_id=tokenizer.eos_token_id)\n    output_og = tokenizer.batch_decode(output_og, skip_special_tokens=True, clean_up_tokenization_spaces=True)[0].replace(prompt, \"\").strip()\n    print(f\"Original model output {i} -\\n---------------------------\\n\", output_og, \"\\n\")\n    \n    results.append({\n        \"Question\": val_data['question'][i],\n        \"Ground_Truth\": val_data['response'][i],\n        \"Finetuned_Response\": output_ft,\n        \"Original_Response\": output_og\n    })\n\ndf = pd.DataFrame(results)\ndf.to_csv(\"hinglish_evaluation.csv\")","metadata":{"id":"3f0277c3-6c1b-440c-98f3-af550616d16f","outputId":"67a61100-922d-4cea-aeb2-fd2e74592322","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T15:52:07.859585Z","iopub.execute_input":"2025-07-05T15:52:07.860190Z","iopub.status.idle":"2025-07-05T16:00:32.204877Z","shell.execute_reply.started":"2025-07-05T15:52:07.860167Z","shell.execute_reply":"2025-07-05T16:00:32.204117Z"}},"outputs":[{"name":"stdout","text":"Fine-tuned model output 0 -\n---------------------------\n <|system|>\nYou are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user \n<|user|>\nCOVID-19 ke baad India mein social media privacy ko lekar kitni tension badh gayi hai? \n<|assistant|>\nAbsolutely, COVID-19 ke baad India mein social media privacy ko kyun zyada tension ho sakta hai?  Yeh toh aapko samjho:\n\n1.  **Sabse bada khatra hai data privacy:**  India mein aapko yeh samajhna hota hai ki aapko kya kya data privacy se bhi chal raha hai.  Jab aap social media platforms ko use karte ho, woh data aapke liye safe rakhte hain.  Lekin jab aap COVID-19 ko track karte ho, woh aapke liye data bahut sensitive ho jaata hai.  Isliye, aapko yeh sabse zyada tension ho sakta hai.\n\n2.  **Privacy ko sabse bada issue hai:**  India mein privacy bahut zyada important hai.  Yeh bahut aapki saath bhi chalta hai.  Jab aap privacy ko bhi uthaate ho, woh aapke liye bhi bahut zyada respect ho jaata hai.  Privacy ka bahut sawaal hai, especially jab aap data privacy se bhi chal rahe ho.\n\n3.  **Tracking pe bhi bahut problem:**  Social media platforms track karta hai, woh aapke liye bhi bahut zyada bhi bhi bhi bhi zyada ho sakta hai.  Aap kisi ko track karte ho, woh aapke liye bhi bhi bhi bhi \n\nOriginal model output 0 -\n---------------------------\n <|system|>\nYou are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user \n<|user|>\nCOVID-19 ke baad India mein social media privacy ko lekar kitni tension badh gayi hai? \n<|assistant|>\nYes, COVID-19 has significantly impacted social media privacy in India. With the lockdown in place, people have been using social media more than ever before to stay connected with friends and family, but also to monitor their health and stay informed about the pandemic.\n\nAs a result, there has been a rise in the number of users reporting their social media accounts being hacked or compromised, with some even reporting that their personal information, including their phone numbers, addresses, and bank details, has been leaked.\n\nThis has led to concerns about the privacy and security of social media users in India, particularly during a pandemic when people are using social media to stay connected and informed.\n\nFurthermore, the COVID-19 pandemic has also led to an increase in cybercrime, with fraudulent activity on social media platforms increasing in recent months. This has led to concerns about the safety of users' personal and financial information on social media platforms.\n\nIn short, while social media has provided a valuable service during the pandemic, it has also raised concerns about the privacy and security of social media users in India. \n\nFine-tuned model output 1 -\n---------------------------\n <|system|>\nYou are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user \n<|user|>\nPhotos aur posts mein tagging se related privacy ke kya issues hain? \n<|assistant|>\nAbsolutely! Tagging is a common feature on social media platforms like Instagram, Facebook, and Twitter. It's a way to organize your content and make it easier to find.  But, there are a few things you need to be aware of when it comes to privacy:\n\n1.  **Tagging is Public:**  Jab tagging karo, toh bhi bhi kuch information public ho jaayega.  Isme kya hota hai?  Kya kya?  Photos, posts, comments, likes, followers, ya bhi?  Yeh information public ho jaayega.  Privacy settings set karne ke liye bhi important hai.\n\n2.  **Tagging aka \"Sharing\" is Shared:**  Jab user kisi ko tag karo, toh bhi bhi kuch information share ho jaayega.  Isme kya hota hai?  User ko kuch information, kuch kuch, kuch kuch, bhi share ho jaayega.  Privacy settings set karne ke liye bhi important hai.\n\n3.  **Tagging aka \"Sharing\" is Public:**  Jab user kisi ko tag karo, toh bhi bhi kuch information share ho jaayega.  Isme kya hota hai?  User ko kuch information, kuch kuch, kuch kuch, bhi share ho jaayega.  Privacy settings set karne ke liye bhi important hai.\n\n4.  **Tagging aka \"Sharing\" is Personal:**  Jab user kisi ko tag karo, toh bhi user ko kuch information share ho jaayega.  Isme kya hota hai? \n\nOriginal model output 1 -\n---------------------------\n <|system|>\nYou are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user \n<|user|>\nPhotos aur posts mein tagging se related privacy ke kya issues hain? \n<|assistant|>\nYes, there are several privacy issues that arise when tagging posts or photos on social media platforms. Here are some common issues and how they can be resolved:\n\n1. Social media platforms' terms of service: Some social media platforms have their own terms of service, which can specify the type of data that they collect and how it's used. Make sure to read and understand the terms of service of the platform you're using before tagging your posts or photos.\n\n2. Third-party tools: Some third-party tools, like social media management apps or photo editing apps, may have access to your social media data, including your profile information, photos, and posts. Make sure to read and understand the terms of service of the tools you're using before using them.\n\n3. Social media platform privacy settings: Some social media platforms have privacy settings that you can use to control who can see your posts or photos. Make sure to understand and follow these settings to avoid unwanted exposure.\n\n4. Social media platforms' policies: Social media platforms may have policies that govern how they handle user data, such as how they use it for advertising or how they protect user privacy. Make sure to read and understand these policies to avoid violating them.\n\n5. Changes in privacy settings: Social media platforms may change their privacy settings over time, so make sure to check and update your privacy settings regularly to ensure that your data is protected.\n\n6. Social media privacy settings: Finally, be sure to check and understand your social media privacy settings to ensure that your data is not being shared with unauthorized third parties. This can be done by visiting your account settings and reviewing the privacy settings. \n\nFine-tuned model output 2 -\n---------------------------\n <|system|>\nYou are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user \n<|user|>\nIndia mein social media par privacy manage karne ko cultural perspective kaise effect karta hai? \n<|assistant|>\nAbsolutely!  India mein social media ka privacy management culture kuch cheezein hain jo aapko **cultural differences** mein bhi affect karti hain.  Yahaan dekho:\n\n1.  **Language ka difference:**  India mein bahut saare languages hain, jaise Hindi, English, Telugu, Kannada, Tamil, etc.  Yeh language use karte time privacy management ka scene different ho sakta hai.  So, kya kya language use karoge, woh bhi aapke privacy settings aur policies decide kar sakte hain.\n\n2.  **Religion ka difference:**  India mein religion bahut zyada important hai.  So, privacy policies ko aapke religion aur cultural background ke liye bhi **context** bana sakta hai.  For example, Muslims ko bhi aap privacy settings ko **mast** kar sakte hain, jisse aap kya karoge, woh bhi aapke privacy settings ko **follow** kar sakte hain.\n\n3.  **Age ka difference:**  India mein kuch ages mein privacy policies **different** hote hain.  Jab aap **teen** karte hain na, toh privacy policies **young** aapke age mein focus karenge.  Jab aap **elderly** hone mein hain na, toh privacy policies **senior** aapke age mein focus karenge.\n\n4.  **Social media use ka difference:**  India mein social media **different** hain.  Jab aap **social media** \n\nOriginal model output 2 -\n---------------------------\n <|system|>\nYou are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user \n<|user|>\nIndia mein social media par privacy manage karne ko cultural perspective kaise effect karta hai? \n<|assistant|>\nIndia is a country with a rich cultural heritage that values privacy and personal space. The following are some cultural perspectives on social media and privacy in India:\n\n1. Privacy is sacred: In India, privacy is considered to be a sacred concept, and the government has taken several measures to protect it. For instance, the Indian government has passed laws to protect the privacy of individuals, such as the Information Technology (Reasonable Security Practices and Procedures and Sensitive Personal Data and Information) Rules, 2011.\n\n2. Respect for privacy is a social norm: In India, social norms and values emphasize the importance of privacy. People in India tend to value their privacy and respect it. This is reflected in the way people communicate and interact with each other, which often involves keeping their personal lives private.\n\n3. Personal space is significant: In India, personal space is considered to be significant, and people often prefer to keep their personal lives private. This is reflected in the way people communicate and interact with each other, which often involves keeping their personal lives private.\n\n4. Social media use is regulated: In India, social media use is regulated by the government and various social media platforms. The government has passed laws to protect the privacy of individuals, such as the Information Technology (Reasonable Security Practices and Procedures and Sensitive Personal Data and Information) Rules, 2011.\n\n5. Social media is a tool for communication: Social media is a tool for communication, and people in India use it to communicate with each other. However, social media use is not always about privacy, and people use it for various purposes, such as sharing information, connecting with friends and family, and keeping up with current events.\n\nIn conclusion, social media use in India is regulated and \n\nFine-tuned model output 3 -\n---------------------------\n <|system|>\nYou are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user \n<|user|>\nTeenagers mein responsible social media use kaise ensure karein? \n<|assistant|>\nAbsolutely! Teenagers are growing up in a digital world, and social media is an essential part of their daily lives.  Here are some ways in which teenagers can ensure responsible social media use:\n\n1.  \"Online Safety\" is Important - Firstly, teenagers should know about online safety.  It's important to know that their personal information can be hacked, and their privacy is important.  They should also know about phishing scams and how to avoid them.  Teach them to use strong passwords and not to click on suspicious links.\n\n2.  \"Friendship & Relationship\" is Important - Teenagers should learn about social media and how it can impact their relationships.  They should know that cyberbullying and harassment can happen online, and they should be kind and supportive of their friends.  Teach them to be aware of their online behavior and how to handle it.\n\n3.  \"Responsible Use\" is Key - Teenagers should learn how to use social media responsibly.  They should avoid posting personal information, like their phone number or address.  They should also be mindful of their online behavior, like how they interact with others.  Teach them to respect privacy and not to share sensitive information.\n\n4.  \"Communication\" is Important - Teenagers should learn how to communicate effectively online.  They should be mindful of their tone and language when posting.  They should also be aware of how they sound when they're speaking to someone online.  Teach them to use emojis and short sentences when communicating.\n\n5.  \"Buddy System\" is Important - Teenagers should learn how to create a \"buddy system\" on social media.  They should be aware of their \"fri \n\nOriginal model output 3 -\n---------------------------\n <|system|>\nYou are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user \n<|user|>\nTeenagers mein responsible social media use kaise ensure karein? \n<|assistant|>\nTo ensure responsible social media use among teenagers, the following measures can be taken:\n\n1. Set up a social media account with age-appropriate content and privacy settings.\n\n2. Educate teenagers about the negative impact of social media on mental health and addiction.\n\n3. Encourage teenagers to limit their social media usage to a specific time period, such as after school or before bedtime.\n\n4. Encourage teenagers to participate in online safety practices such as password protection, device lockdown, and screen time limits.\n\n5. Provide resources and support for teenagers who struggle with social media addiction or self-harm.\n\n6. Monitor teenagers' social media activity and respond promptly to any negative comments or behavior.\n\n7. Encourage teenagers to participate in community service or volunteer work to develop social skills and build relationships.\n\n8. Encourage teenagers to participate in extracurricular activities that promote healthy socialization and personal growth.\n\n9. Encourage teenagers to set boundaries with social media and limit their use during school hours or after school hours.\n\n10. Encourage teenagers to seek professional help if they are struggling with social media addiction or self-harm. \n\nFine-tuned model output 4 -\n---------------------------\n <|system|>\nYou are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user \n<|user|>\nSocial media pe live videos daalte rehne se kya risk ho sakte hain? \n<|assistant|>\nAbsolutely! Social media ke live videos, yeh toh ekdum *real* life experience banayein, *real* reactions bhi denge.  Toh kya kya hota hai, yeh *fake* reactions kya karte hain?  Yeh *very* important hai, kyunki social media pe aise videos *really* *live* hote hain.  Toh agar aapke liye bahut *fake* reaction daalte ho, toh kya?\n\n**1. Time lagta hai:**  Agar aapke liye bahut *fake* reaction daalte ho, toh *time* lagta hai.  Real life mein sabse *important* cheez hai time.  Aapke videos *live* hote hain, toh *fake* reaction lagta hai.  Agar aapke liye bahut *fake* reaction daalte ho, toh *time* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi* *bhi \n\nOriginal model output 4 -\n---------------------------\n <|system|>\nYou are a friendly chatbot who always responds in a short, crisp and to-the-point fashion in Hinglish to any query of the user \n<|user|>\nSocial media pe live videos daalte rehne se kya risk ho sakte hain? \n<|assistant|>\nI do not have access to real-time information or insights. However, in general, live videos on social media platforms like facebook, instagram, and twitter can pose a risk to the user's privacy and security. The content of the live video may be captured and shared by the user's friends, followers, or other viewers, who may use it for their own purposes without the user's consent. It is recommended to use caution when sharing personal information or sensitive content in live videos. \n\n","output_type":"stream"}],"execution_count":76},{"id":"cc00bf50-dcda-4209-938d-c6b4ae097176","cell_type":"markdown","source":"We can see the model has clearly improved and is answering to the user in Hinglish most of the time. However with training on more epochs and larger dataset, the performance of the fine-tuned model can improve tremendously.","metadata":{}}]}